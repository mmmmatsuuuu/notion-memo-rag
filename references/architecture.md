# Architecture

## 1. 目的

本アプリは、Notionに蓄積された読書メモを
「意味検索 + 根拠付きサジェスト」により、
思考の起爆剤として活用するための
個人用RAGシステムである。

これはチャットボットではない。
会話を続けることが目的ではない。

目的は：

- 文脈から関連知見を引き出す
- 関連知見を問いに沿って再整理する
- 原典（一次資料）へ辿り着く導線を作る
- 思考を加速する

---

## 2. 基本思想

### 2.1 主役は「原文断片」

生成AIは補助。
主役は自分のメモ。

表示するのは：

- メモ原文（先頭400文字）
- 出典リンク
- 本情報

### 2.2 1メモ = 1ベクトル

MVPでは分割（chunking）は行わない。
精度改善は後回し。

### 2.3 検索件数は2段階

- `fetch_k = 20`（取りこぼしを減らす）
- `answer_k = 8`（生成で使う根拠を絞る）
- 取得件数と生成件数を分離して精度と網羅性を両立する

---

## 3. システム構成

### 3.1 技術スタック

- Next.js (App Router)
- Supabase (Postgres + pgvector)
- Supabase Auth (Google)
- OpenAI Embedding API (text-embedding-3-small)
- OpenAI Chat Completions API (gpt-5-mini)
- Notion API
- Vercel

---

## 4. データフロー

### 4.1 同期（インデックス作成）

1. Notion Data Sourceから `id` と `last_edited_time` を取得（`limit=50` または `all`）
2. Supabaseから候補IDの `id` と `last_edited_time` を取得
3. 未登録または更新済みページのみ差分抽出
4. 差分対象のブロックを再帰取得
5. テキストを改行結合
6. embedding生成
7. Supabaseへupsert

保存単位：
1ページ = 1レコード

---

### 4.2 検索 + 生成（`/api/assist`）

1. ログイン後、`/` 画面の下部固定ツールバーで `query` を入力
2. embedding生成
3. Supabaseで近傍検索
4. `fetch_k=20` を取得
5. 上位 `answer_k=8` を生成コンテキストに採用
6. 生成文は問いに対して自然言語で回答し、根拠カード参照を含める
7. 根拠カードを表示（`used_memo_ids`を返す）
8. ツールバーから `/admin` へ遷移可能

---

### 4.3 一次資料導線

- クエリ候補生成（3〜6件、単語組み合わせ）
- 各結果カード内にGoogle Scholarリンク表示
- Webスクレイピングは行わない

---

## 5. セキュリティ設計

- 個人専用（ALLOWED_EMAIL制限）
- 秘密鍵はサーバー側のみ
- Service Role Keyはクライアントに渡さない

---

## 6. 非目標（MVPでやらないこと）

- メモ分割（chunking）
- タグフィルタ
- 自動バックグラウンド同期
- Web検索の自動取得
- 自律的な長時間チャット

---

## 7. 将来の拡張余地

- chunking導入
- ハイブリッド検索（タグ + ベクトル）
- 再ランキング
- 関連メモのクラスタリング表示
- 自動要約保存

---

## 8. 設計原則

- まず動くものを作る
- 認知負荷を下げる
- UXを観察してから改善する
- 過剰設計を避ける

---

## 9. このアプリの定義

これは「思考支援ツール」である。

知識の断片を呼び起こし、
原典へ辿り着くための装置である。

思考は自分が行う。
